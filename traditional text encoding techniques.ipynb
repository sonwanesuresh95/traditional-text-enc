{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References - [https://medium.com/analytics-vidhya/nlp-text-encoding-a-beginners-guide-fa332d715854#:~:text=Text%20encoding%20is%20a%20process,out%20the%20context%20of%20sentences.]\n",
    "article is severly flawed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of traditional text encoding techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_corpus = [\"this is a good phone phone\",\n",
    "                  \"this is a bad mobile mobile\",\n",
    "                  \"she is a good good cat\",\n",
    "                  \"he has a bad temper temper\",\n",
    "                  \"this mobile phone phone is not good good\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(set(\" \".join(document_corpus).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'good', 'bad', 'temper', 'this', 'mobile', 'is', 'phone', 'cat', 'has', 'a', 'not', 'he']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words\n",
    "Use whole corpus matrix to represent each sentence in form of 1 & 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encodings = []\n",
    "for sentence in document_corpus:\n",
    "    encoding = []\n",
    "    for word in corpus:\n",
    "        if word in sentence.split(\" \"):\n",
    "            encoding.append(1)\n",
    "        else:\n",
    "            encoding.append(0)\n",
    "    all_encodings.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       " [0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count based Bag of words (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encodings = []\n",
    "for sentence in document_corpus:\n",
    "    encoding = []\n",
    "    for word in corpus:\n",
    "        if word in sentence.split(\" \"):\n",
    "            encoding.append(sentence.split(\" \").count(word))\n",
    "        else:\n",
    "            encoding.append(0)\n",
    "    all_encodings.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 2, 1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       " [0, 2, 0, 0, 1, 1, 1, 2, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(t,d):\n",
    "    return d.count(t)/len(set(d.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(t,d,D):\n",
    "    number_of_tokens = len(corpus)\n",
    "    number_of_documents_with_t_in_them = sum([1 if t in d else 0 for d in D])\n",
    "    df = number_of_documents_with_t_in_them/number_of_tokens\n",
    "    idf = 1/df\n",
    "    return np.log(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(t,d,D):\n",
    "    return tf(t,d)*idf(t,d,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encodings = []\n",
    "for sentence in document_corpus:\n",
    "    encoding = []\n",
    "    for word in corpus:\n",
    "        if word in sentence.split(\" \"):\n",
    "            encoding.append(tf_idf(word,sentence,document_corpus))\n",
    "        else:\n",
    "            encoding.append(0)\n",
    "    all_encodings.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0.2932674137586854, 0, 0, 0.2932674137586854, 0, 0.4714619985366585, 0.7487208707606365, 0, 0, 0.23573099926832924, 0, 0], [0, 0, 0.37436043538031827, 0, 0.2932674137586854, 0.7487208707606365, 0.4714619985366585, 0, 0, 0, 0.4714619985366585, 0, 0], [0.5129898714923073, 0.5865348275173708, 0, 0, 0, 0, 0.23573099926832924, 0, 0.5129898714923073, 0, 0.4714619985366585, 0, 0], [0, 0, 0.37436043538031827, 1.0259797429846147, 0, 0, 0, 0, 0, 0.5129898714923073, 0.7071929978049877, 0, 0.37436043538031827], [0, 0.4887790229311423, 0, 0, 0.24438951146557114, 0.31196702948359856, 0.3928849987805487, 0.6239340589671971, 0, 0, 0, 0.42749155957692275, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(all_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
